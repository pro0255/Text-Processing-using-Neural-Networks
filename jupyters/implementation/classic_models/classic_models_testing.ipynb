{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of Classic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def adding_module_path():\n",
    "    module_path = os.path.abspath(os.path.sep.join([\"..\"]*3))\n",
    "\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "adding_module_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vectorizers.classic.bow_vectorizer import BoWVectorizer\n",
    "from src.vectorizers.classic.tfidf_vectorizer import TfidfVectorizer\n",
    "from src.vectorizers.transformer.bert_base_vectorizer import BertBaseUncasedVectorizer\n",
    "from src.vectorizers.transformer.distil_bert_base_vectorizer import DistilBertBaseUncasedVectorizer\n",
    "from src.vectorizers.transformer.electra_small_vectorizer import ElectraSmallVectorizer\n",
    "from src.vectorizers.embedding.glove_vectorizer import GloveVectorizer\n",
    "from src.vectorizers.embedding.word2vec_vectorizer import Word2VecVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.classic.linear import LinearClassifier\n",
    "from src.models.classic.naive_bayes import NaiveBayes\n",
    "from src.models.classic.random_forest import RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.preprocessing_factory import PreprocessingFactory, PreprocessingType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating shorting method with min = 3\n",
      "Creating lemma method with instance <WordNetLemmatizer>\n"
     ]
    }
   ],
   "source": [
    "factory = PreprocessingFactory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.create_path_to_gutenberg import get_path_to_gutenberg_sets\n",
    "from src.data_loading.get_dataset_object_from import get_datasets\n",
    "from src.config.config import PATH_TO_DATASET_FOLDER_TEST\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from=C:\\Users\\Vojta\\Desktop\\diploma\\data_test\\gutenberg\\10Authors\\Sentence3\\train.csv\n",
      "Loading dataset from=C:\\Users\\Vojta\\Desktop\\diploma\\data_test\\gutenberg\\10Authors\\Sentence3\\valid.csv\n",
      "Loading dataset from=C:\\Users\\Vojta\\Desktop\\diploma\\data_test\\gutenberg\\10Authors\\Sentence3\\test.csv\n"
     ]
    }
   ],
   "source": [
    "test_corpus = np.array([\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "])\n",
    "y = np.array([0,0,0,0])\n",
    "\n",
    "path_data, path_authors = get_path_to_gutenberg_sets(10, 3, PATH_TO_DATASET_FOLDER_TEST)\n",
    "train, valid, test = get_datasets(path_data, ';', factory.create(PreprocessingType.Default))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.from_dataset_arrays import from_dataset_dataframe\n",
    "from src.config.config import TEXT_COLUMN, LABEL_COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = from_dataset_dataframe(train)\n",
    "test_df = from_dataset_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miss nugent received information civil bow ren...</td>\n",
       "      <td>1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hour familiar place instinct method true trave...</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twin accepted invitation reception progress vo...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cried sheriff like father master ask boy like man</td>\n",
       "      <td>3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wonder said offended kybird banns week murmure...</td>\n",
       "      <td>1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>picked remains laid palm said poor little anty...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>mean mean seventy naturally ninety</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>illustration try said little john whereabouts ...</td>\n",
       "      <td>3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>mark telford john gladney thing pleasant consi...</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>murmur disapproval arose word chief haruspices...</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    miss nugent received information civil bow ren...   1865\n",
       "1    hour familiar place instinct method true trave...   1285\n",
       "2    twin accepted invitation reception progress vo...     53\n",
       "3    cried sheriff like father master ask boy like man   3840\n",
       "4    wonder said offended kybird banns week murmure...   1865\n",
       "..                                                 ...    ...\n",
       "695  picked remains laid palm said poor little anty...     53\n",
       "696                 mean mean seventy naturally ninety     53\n",
       "697  illustration try said little john whereabouts ...   3840\n",
       "698  mark telford john gladney thing pleasant consi...   1285\n",
       "699  murmur disapproval arose word chief haruspices...   1800\n",
       "\n",
       "[700 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looked laughed recognized strange guest approa...</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awoke morning joyful eager start home company ...</td>\n",
       "      <td>3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forest haunt run prime repast paying blow yoke...</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quid lent said prout pained voice said carter ...</td>\n",
       "      <td>1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>came day clipped thread touch lip lay cold ear...</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>look fellow toe make comfortable heritage assa...</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>mark telford ambition child ride horse man lik...</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>superficial listener blame music discord heard...</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>historical novel georg ebers index edited davi...</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>earlier edition uarda published rapid successi...</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    looked laughed recognized strange guest approa...   1800\n",
       "1    awoke morning joyful eager start home company ...   3840\n",
       "2    forest haunt run prime repast paying blow yoke...    520\n",
       "3    quid lent said prout pained voice said carter ...   1865\n",
       "4    came day clipped thread touch lip lay cold ear...    520\n",
       "..                                                 ...    ...\n",
       "145  look fellow toe make comfortable heritage assa...   1800\n",
       "146  mark telford ambition child ride horse man lik...   1285\n",
       "147  superficial listener blame music discord heard...   1800\n",
       "148  historical novel georg ebers index edited davi...   1800\n",
       "149  earlier edition uarda published rapid successi...   1800\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding and classic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Word2VecVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed=418, counter=18102, accuracy=2.3091371119213346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(418, 18102, 2.3091371119213346)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(train_df[TEXT_COLUMN])\n",
    "vectorizer.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed=103, counter=3553, accuracy=2.898958626512806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(103, 3553, 2.898958626512806)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectorizer.fit_transform(test_df[TEXT_COLUMN])\n",
    "vectorizer.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[LABEL_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test = test_df[LABEL_COLUMN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertBaseUncasedVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = bert.fit_transform(train)\n",
    "X_test, y_test = bert.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.experiment_evaluate import ExperimentEvaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = ExperimentEvaluate(\"test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.calc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3,\n",
       " 'F1': 0.3,\n",
       " 'Precision': 0.3,\n",
       " 'Recall': 0.3,\n",
       " 'ConsfusionMatrix': array([[11,  0,  0,  2,  0,  0,  0,  2,  0,  0],\n",
       "        [13,  0,  0,  0,  0,  0,  0,  2,  0,  0],\n",
       "        [10,  0,  0,  3,  0,  0,  0,  2,  0,  0],\n",
       "        [ 8,  0,  0,  5,  0,  0,  0,  1,  1,  0],\n",
       "        [ 8,  0,  0,  6,  0,  0,  0,  0,  0,  1],\n",
       "        [ 4,  0,  0,  1,  0, 10,  0,  0,  0,  0],\n",
       "        [13,  0,  0,  2,  0,  0,  0,  0,  0,  0],\n",
       "        [ 6,  0,  0,  0,  0,  0,  0,  7,  1,  1],\n",
       "        [ 3,  0,  0,  1,  0,  0,  0,  1, 10,  0],\n",
       "        [ 9,  0,  0,  4,  0,  0,  0,  0,  0,  2]], dtype=int64)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.state"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "deac0217989ddcfa4345bc236e90ab22a38c5ad7d8517b867015082eaa3f672d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
